{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kshn12017/Emotion-detection/blob/main/Emotion_Detection_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWal8AXqYK-d"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEEUOIyjch3P"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SvVTzeRl1KD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Step 1: Load the dataset from CSV\n",
        "data = pd.read_csv('/content/drive/MyDrive/TCS/Dataset.csv')\n",
        "\n",
        "sentences = data['sentence'].tolist()\n",
        "emotions = data['emotion'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocess the text\n",
        "def resolve_double_negation(sentence):\n",
        "    # Pattern to match double negations\n",
        "    pattern = r\"\\b(?:not|n't)\\s+\\b(?:no|never|nobody|nothing|none|nowhere)\\b\"\n",
        "\n",
        "    # Replace double negations with positive counterparts\n",
        "    resolved_sentence = re.sub(pattern, ' ', sentence)\n",
        "    return resolved_sentence\n",
        "\n",
        "# Apply double negation resolution to each sentence\n",
        "sentences = [resolve_double_negation(sentence) for sentence in sentences]\n",
        "sentences = [sentence.lower() for sentence in sentences]\n",
        "\n",
        "# Convert abbreviations to their full forms\n",
        "abbreviations = {\n",
        "    'nxt': 'next',\n",
        "    '2mrw': 'tomorrow',\n",
        "    'r': 'are',\n",
        "    'gd': 'good',\n",
        "    'ig': 'i guess',\n",
        "    'idk': 'i dont know',\n",
        "    'lol': 'laughing out loud',\n",
        "    'omg': 'oh my god',\n",
        "    'btw': 'by the way',\n",
        "    'brb' : 'be right back',\n",
        "    'afk' : 'away from keyboard',\n",
        "    'fyi' : 'for your information',\n",
        "    'idk' : 'i dont know',\n",
        "    'tbh' : 'to be honest',\n",
        "    'imo' : 'in my opinion',\n",
        "    'imho' : 'in my humble opinion',\n",
        "    'rofl' : 'rolling on the floor laughing',\n",
        "    'lmao' : 'laughing my ass off',\n",
        "    'tmi' : 'too much information',\n",
        "    'afaik' : 'as far as i know',\n",
        "    'nvm' : 'never mind',\n",
        "    'jk' : 'just kidding',\n",
        "    'asap' : 'as soon as possible',\n",
        "    'fyr' : 'for your reference',\n",
        "    'eta' : 'estimated time of arrival',\n",
        "    'fwiw' : 'for what its worth'\n",
        "    # Add more abbreviations as necessary\n",
        "}\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "    sentence = sentences[i]\n",
        "    for abbreviation, full_form in abbreviations.items():\n",
        "        sentence = sentence.replace(abbreviation, full_form)\n",
        "    sentences[i] = sentence.lower()"
      ],
      "metadata": {
        "id": "Pl4cjgV_ZR8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Tokenize and encode the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "max_sequence_length = max(len(sequence) for sequence in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
      ],
      "metadata": {
        "id": "vgSfQBPNZWHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Prepare the labels\n",
        "# Convert emotions to one-hot encoding\n",
        "emotions_mapping = {\n",
        "    'anger': 0,\n",
        "    'boredom': 1,\n",
        "    'empty': 2,\n",
        "    'enthusiasm': 3,\n",
        "    'fun': 4,\n",
        "    'happiness': 5,\n",
        "    'hate': 6,\n",
        "    'love': 7,\n",
        "    'neutral': 8,\n",
        "    'relief': 9,\n",
        "    'sadness': 10,\n",
        "    'surprise': 11,\n",
        "    'worry': 12,\n",
        "    'sarcastic': 13\n",
        "}\n",
        "\n",
        "labels = [emotions_mapping[emotion] for emotion in emotions]\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(padded_sequences, one_hot_labels, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "dvT0JuFtZZRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define the sarcasm detection model\n",
        "sarcasm_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "sarcasm_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def check_sarcasm(sentence):\n",
        "    input_ids = sarcasm_tokenizer.encode(sentence, truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
        "    predictions = sarcasm_model(input_ids)[0]\n",
        "    predicted_label = tf.argmax(predictions, axis=1).numpy()[0]\n",
        "    labels = ['Non-sarcastic', 'Sarcastic']\n",
        "    sarcasm_label = labels[predicted_label]\n",
        "    return sarcasm_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U72bPVrkZci8",
        "outputId": "d344b8a3-2545-4cef-b104-2cd38508b68c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Define the emotion detection model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 100, input_length=max_sequence_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hXML-kKlZfCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Train the emotion detection model\n",
        "model.fit(train_sentences, train_labels, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjNh5lf8ZiBr",
        "outputId": "c859a3da-8b99-4a96-ee89-42d59fae2998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1003/1003 [==============================] - 215s 200ms/step - loss: 2.0297 - accuracy: 0.3008\n",
            "Epoch 2/10\n",
            "1003/1003 [==============================] - 186s 186ms/step - loss: 1.7550 - accuracy: 0.4098\n",
            "Epoch 3/10\n",
            "1003/1003 [==============================] - 191s 190ms/step - loss: 1.3689 - accuracy: 0.5461\n",
            "Epoch 4/10\n",
            "1003/1003 [==============================] - 190s 190ms/step - loss: 0.9575 - accuracy: 0.6981\n",
            "Epoch 5/10\n",
            "1003/1003 [==============================] - 192s 191ms/step - loss: 0.6538 - accuracy: 0.7969\n",
            "Epoch 6/10\n",
            "1003/1003 [==============================] - 193s 192ms/step - loss: 0.4543 - accuracy: 0.8584\n",
            "Epoch 7/10\n",
            "1003/1003 [==============================] - 190s 189ms/step - loss: 0.3324 - accuracy: 0.8974\n",
            "Epoch 8/10\n",
            "1003/1003 [==============================] - 191s 190ms/step - loss: 0.2648 - accuracy: 0.9176\n",
            "Epoch 9/10\n",
            "1003/1003 [==============================] - 185s 185ms/step - loss: 0.2127 - accuracy: 0.9329\n",
            "Epoch 10/10\n",
            "1003/1003 [==============================] - 194s 194ms/step - loss: 0.1802 - accuracy: 0.9445\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x794b109fc7f0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Predict emotions for new sentences\n",
        "def predict_emotion(sentence):\n",
        "    preprocessed_sentence = sentence.lower()\n",
        "    sequence = tokenizer.texts_to_sequences([preprocessed_sentence])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length)\n",
        "    prediction = model.predict(padded_sequence)[0]\n",
        "    emotion_index = np.argmax(prediction)\n",
        "    predicted_emotion = list(emotions_mapping.keys())[emotion_index]\n",
        "\n",
        "    # Check for sarcasm and predict emotion accordingly\n",
        "    sarcasm_label = check_sarcasm(sentence)\n",
        "    if sarcasm_label == 'Sarcastic' and predicted_emotion != 'Sarcastic':\n",
        "        predicted_emotion = 'Sarcastic'\n",
        "\n",
        "    return predicted_emotion"
      ],
      "metadata": {
        "id": "qRQIzAtQZkAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Evaluate the model on the testing set\n",
        "loss, accuracy = model.evaluate(test_sentences, test_labels)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ7WR8phZu_K",
        "outputId": "e826eaa7-1b38-44a6-bed9-24da40b4da3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "251/251 [==============================] - 13s 50ms/step - loss: 1.0157 - accuracy: 0.8185\n",
            "Test Accuracy: 0.8185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSLNLpz8lFQL",
        "outputId": "ef4f76f4-1eaa-4306-9a42-0a693b197fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 195ms/step\n",
            "Emotion: happiness\n"
          ]
        }
      ],
      "source": [
        "#Predicting the emotion of a new sentence\n",
        "sentence = \"It was a good experiene..\"\n",
        "emotion = predict_emotion(sentence)\n",
        "print(f\"Emotion: {emotion}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}